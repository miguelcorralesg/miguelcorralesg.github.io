---
layout: distill
title: RockGAN
description: 3D Porous media generation using WGAN-GP.
img: assets/img/rockgan_logo.png
importance: 2
category: work
date: 2022-10-31

authors:
  - name: Miguel Corrales
    # url: "https://en.wikipedia.org/wiki/Albert_Einstein"
    affiliations:
      name: KAUST

bibliography: project_porous_media.bib

toc:
  - name: What will you find here?
  - name: Workflow
    # if a section has subsections, you can add them as follows:
    # subsections:
    #   - name: Example Child Subsection 1
    #   - name: Example Child Subsection 2
  - name: Results
    subsections:
      -name: Real samples
      -name: Generated samples
  - name: Publication

---

Welcome to the RockGAN project :metal: :metal: :metal:

The 3D porous media generation using a Wasserstein GAN with gradient penalty **(here named as RockGAN)** was born as part of a course project at KAUST. The main inspiration comes from the novel ideal of Lukas Mosser <d-cite key="PhysRevE.96.043309"></d-cite>, which consisted of applying Generative Adversarial Networks (GANs) as a new tool to generate random samples corresponding to a rock sample of interest rather than applying the conventional multi-point statistics <d-cite key="OKABE2005121"></d-cite>.

# What will you find here? 
The reader will find a short description of the project delivered in a friendly way and a nutshell. For more technical details, we suggest reading the conference paper submitted <d-cite key="eage:/content/papers/10.3997/2214-4609.2022616005"></d-cite> , which also contains the GitHub repository. For this project, we simply started trying to produce quality samples in 2D for the Berea and Beadpack dataset. The architecture was slightly different from what you will see in the upcoming sections. However, there is no so much attention if only 2D samples are reproduced. In this study, we satisfy the following questions: 
- How should we create our dataset? 
- What kind of architecture should we implement?
- What loss function is more suitable?
- Should we use normalization in both networks and which kind of it?
- Is it possible to add physical constraints in the loss to make more representative samples? 

Just remember that GANs are quite of trial and error :D. I hope you enjoy it!

# Workflow
Here, we take a similar but different approach. Our work is based on some key points from the paper  from Tego Karras at NVIDIA <d-cite key="karras2017progressive"></d-cite>. The main ideas are: 
- Growing progressively from low to high dimension (Critic in the opposite way).
- Use normalization just in one of the layers. 
- We tested different activation functions, at the end, better results were achieve using GELU. 
- We used the Wasserstein formulation with gradient penalty. 

The main workflow idea is expressed in the following figure:

{% include figure.html path="assets/img/project_rockgan/architecture.png" title="example image" class="RockGAN workflow." %}
<div class="caption">
    Training RockGAN workflow proposed.
</div>

# Results
Let us compare the results obtained with RockGAN and the training data of the Berea dataset.

## Real samples
{% include figure.html path="assets/img/project_rockgan/training_3D_samples_cube.png" title="Training 3D samples" class="RockGAN workflow." %}
<div class="caption">
    Random samples corresponding to the training dataset.
</div>

## Generated samples
{% include figure.html path="assets/img/project_rockgan/RockGAN_3D_samples_cube.png" title="Samples generated by RockGAN" class="RockGAN workflow." %}
<div class="caption">
    Samples generated by RockGAN.
</div>

# Publication
More details about the project could be found on the following publication:
[RockGAN](https://www.earthdoc.org/content/papers/10.3997/2214-4609.2022616005). 



